{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cedf84f-e8b3-43cf-b784-2f00fe0c8294",
   "metadata": {},
   "source": [
    "# Denoising Demo Notebook\n",
    "\n",
    "Notebook to showcase some denoising methods for electron microscopy images\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2db7b15-fcad-4151-8b92-8fa7c5bcad45",
   "metadata": {},
   "source": [
    "This notebook is intended to be used in Google Colab. <br>\n",
    "If it is used locally all the necessary python packages need to be installed seperataly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875415ed-62cc-4905-bd89-e0dd75af74e6",
   "metadata": {},
   "source": [
    "## How to use this notebook?\n",
    "\n",
    "This notebook contains four image denoising methods. Before each method you need to declare some inputs, like the path to the directory containing your images and some method specific parameters. More information on each method can be found by following the provided links.\n",
    "<br>\n",
    "<br>\n",
    "All methods should be used with .tif images only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711a6d68-bf90-4ab2-be34-330aa59197e7",
   "metadata": {},
   "source": [
    "# 0. Before getting started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf440f4-4516-498b-98b4-34f453b49bae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1627d027-69eb-433f-beae-55dd9201e625",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435a8709-5b39-44ba-89eb-e2a91a1238dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5ac6e601-2ad9-42ed-957e-8ae28d7b9c8c",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633a911c-cab8-4bf5-a3de-e85b3e6d92be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from tifffile import imread, imsave, imwrite\n",
    "from scipy import ndimage\n",
    "import os\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121c7e3e-c064-4569-b039-075a6ecb72e6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 1. Median Filter\n",
    "\n",
    "(source: https://en.wikipedia.org/wiki/Median_filter) <br>\n",
    "(documentation: https://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.median_filter.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6597df-5154-4dff-a598-7190134ecc7c",
   "metadata": {},
   "source": [
    "## Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6bc426-97ae-4893-9d85-131534f4b61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the input directory containing your source images\n",
    "input_directory = 'images'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a6aff5-be0b-4ef3-8ac2-e3eebc8c4e17",
   "metadata": {},
   "source": [
    "### Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0584db-f8b2-407f-ac65-f7c0e1301cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the size of the kernel used for denoising:\n",
    "# the bigger the kernel, the more denoising & blurring\n",
    "kernel_size=30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8896aa4a-174f-49d4-b2c9-a88f0fb3bfa8",
   "metadata": {},
   "source": [
    "## Denoising function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253290a0-8252-4ac2-a5f8-0781c919d838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the output directory if it doesn't exist\n",
    "median_output_directory = 'median_results'\n",
    "if not os.path.exists(median_output_directory):\n",
    "    os.makedirs(median_output_directory)\n",
    "\n",
    "# create empty list where names of all processed files will be saved\n",
    "median_file_list=[]\n",
    "\n",
    "# Loop through all files in the input directory\n",
    "for filename in os.listdir(input_directory):\n",
    "    if filename.endswith(\".tif\"):\n",
    "        # Construct the full path for the input image\n",
    "        input_path = os.path.join(input_directory, filename)\n",
    "\n",
    "        # Read the image\n",
    "        img = imread(input_path)\n",
    "\n",
    "        # Apply the median filter\n",
    "        filtered = ndimage.median_filter(img, size=kernel_size)\n",
    "\n",
    "        # Construct the full path for the output image\n",
    "        output_path = os.path.join(median_output_directory, filename)\n",
    "\n",
    "        # Save the filtered image\n",
    "        imwrite(output_path, filtered)\n",
    "\n",
    "        # add to list\n",
    "        median_file_list.append([input_path, output_path])\n",
    "        \n",
    "        print(f\"Processed: {filename} and saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df390f38-84a1-4ac5-a85b-5857e9baa574",
   "metadata": {},
   "source": [
    "## Display a random pair of noisy and denoised images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec1b54d-0aaa-4c33-87dc-a9b493f0c91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get ramdom pair of original und processed images\n",
    "random_pair=random.choice(median_file_list)\n",
    "orig_img=imread(random_pair[0])\n",
    "median_img=imread(random_pair[1])\n",
    "\n",
    "# display images\n",
    "f=plt.figure(figsize=(16,8))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(orig_img, interpolation='nearest', cmap='gray')\n",
    "plt.title('Original')\n",
    "plt.axis('off');\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(median_img, interpolation='nearest', cmap='gray')\n",
    "plt.title('Median filter')\n",
    "plt.axis('off');\n",
    "plt.subplots_adjust(wspace=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53300843-5d6e-47f1-b204-7c2ee328ea7d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 2. Anisotropic Diffusion\n",
    "\n",
    "(source: https://en.wikipedia.org/wiki/Anisotropic_diffusion) <br>\n",
    "(original code: https://pastebin.com/sBsPX4Y7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7beed4-67e4-4f7d-bff1-47bff6eadc68",
   "metadata": {},
   "source": [
    "## Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5c825f-bda5-4b72-b35c-e40dc7af6d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the input directory containing your source images\n",
    "input_directory = 'images'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547acdac-b3f5-42e8-91a5-927a8a8a5a65",
   "metadata": {},
   "source": [
    "### Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb50b434-5f6d-4640-9797-d0f48a186d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of Iterations\n",
    "niter = 100\n",
    "\n",
    "step=(1.,1.)\n",
    "gamma=0.1\n",
    "kappa=50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9303574-907d-4691-a26e-2b2356afc4b0",
   "metadata": {},
   "source": [
    "## Denoising function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ffc2e4-3409-4940-bfd1-2a386031381b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the output directory if it doesn't exist\n",
    "anisodif_output_directory = 'anisodif_results'\n",
    "if not os.path.exists(anisodif_output_directory):\n",
    "    os.makedirs(anisodif_output_directory)\n",
    "\n",
    "# create empty list where names of all processed files will be saved\n",
    "anisodif_file_list=[]\n",
    "\n",
    "# Loop through all files in the input directory\n",
    "for filename in os.listdir(input_directory):\n",
    "    if filename.endswith(\".tif\"):\n",
    "        # initialize output array\n",
    "        img = img.astype('float32')\n",
    "        imgout = img.copy()\n",
    " \n",
    "        # initialize some internal variables\n",
    "        deltaS = np.zeros_like(imgout)\n",
    "        deltaE = deltaS.copy()\n",
    "        NS = deltaS.copy()\n",
    "        EW = deltaS.copy()\n",
    "        gS = np.ones_like(imgout)\n",
    "        gE = gS.copy()\n",
    "\n",
    "        for ii in range(niter):\n",
    "         \n",
    "            # calculate the diffs\n",
    "            deltaS[:-1,: ] = np.diff(imgout,axis=0)\n",
    "            deltaE[: ,:-1] = np.diff(imgout,axis=1)\n",
    "            gS = 1./(1.+(deltaS/kappa)**2.)/step[0]\n",
    "            gE = 1./(1.+(deltaE/kappa)**2.)/step[1]\n",
    "         \n",
    "            # update matrices\n",
    "            E = gE*deltaE\n",
    "            S = gS*deltaS\n",
    "         \n",
    "            # subtract a copy that has been shifted 'North/West' by one\n",
    "            # pixel. don't as questions. just do it. trust me.\n",
    "            NS[:] = S\n",
    "            EW[:] = E\n",
    "            NS[1:,:] -= S[:-1,:]\n",
    "            EW[:,1:] -= E[:,:-1]\n",
    "         \n",
    "            # update the image\n",
    "            imgout += gamma*(NS+EW)\n",
    "        \n",
    "            iterstring = \"Iteration %i\" %(ii+1)\n",
    "\n",
    "        # Construct the full path for the output image\n",
    "        output_path = os.path.join(anisodif_output_directory, filename)\n",
    "        \n",
    "        # Save the filtered image\n",
    "        imwrite(output_path, imgout)\n",
    "\n",
    "        # add to list\n",
    "        anisodif_file_list.append([input_path, output_path])\n",
    "        \n",
    "        print(f\"Processed: {filename} and saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8451b166-8889-472b-87cb-3d3a4e2fcb77",
   "metadata": {},
   "source": [
    "## Display a random pair of noisy and denoised images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2539cdd-f447-4ac6-93fd-a6ae382fc96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get ramdom pair of original und processed images\n",
    "random_pair=random.choice(anisodif_file_list)\n",
    "orig_img=imread(random_pair[0])\n",
    "median_img=imread(random_pair[1])\n",
    "\n",
    "# display images\n",
    "f=plt.figure(figsize=(16,8))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(orig_img, interpolation='nearest', cmap='gray')\n",
    "plt.title('Original')\n",
    "plt.axis('off');\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(median_img, interpolation='nearest', cmap='gray')\n",
    "plt.title('Anisotropic Diffusion, ' + iterstring)\n",
    "plt.axis('off');\n",
    "plt.subplots_adjust(wspace=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea98dfd-5867-4739-9942-07dec99159e2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 3. Non-local Means\n",
    "(source: https://en.wikipedia.org/wiki/Non-local_means) <br>\n",
    "(documentation: https://scikit-image.org/docs/stable/api/skimage.restoration.html#skimage.restoration.denoise_nl_means)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1031e206-4943-4092-906e-2f7691827037",
   "metadata": {},
   "source": [
    "## Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac99d49f-52f3-43f0-801f-e179814ddfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the input directory containing your source images\n",
    "input_directory = 'images'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3c8b77-80f1-42ef-a94b-8288a6b6b80a",
   "metadata": {},
   "source": [
    "### Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e956dcf-3339-4839-914f-c9351efedfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# size of the patches used for denoising\n",
    "size_of_patches = 7\n",
    "\n",
    "# Maximal distance in pixels where to search patches used for denoising\n",
    "distance_to_patch = 11\n",
    "\n",
    "# Cut-off distance (in gray levels). The higher h, the more permissive one is in accepting patches. \n",
    "# A higher h results in a smoother image, at the expense of blurring features. \n",
    "cut_off_dist=0.8\n",
    "\n",
    "# The standard deviation of the (Gaussian) noise. \n",
    "# We use the estimate_sigma()-function since this is not known\n",
    "# If you want to change this, set sigma here:\n",
    "#sigma_value = \n",
    "# Dont forget to change the function in the following cell!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e569e0-3edf-4f25-a265-6d64cc8f7f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the output directory if it doesn't exist\n",
    "nlmeans_output_directory = 'nlmeans_results'\n",
    "if not os.path.exists(nlmeans_output_directory):\n",
    "    os.makedirs(nlmeans_output_directory)\n",
    "\n",
    "# create empty list where names of all processed files will be saved\n",
    "nlmeans_file_list=[]\n",
    "\n",
    "# Loop through all files in the input directory\n",
    "for filename in os.listdir(input_directory):\n",
    "    if filename.endswith(\".tif\"):\n",
    "        # Construct the full path for the input image\n",
    "        input_path = os.path.join(input_directory, filename)\n",
    "\n",
    "        # Read the image\n",
    "        img = imread(input_path)\n",
    "        \n",
    "        # Add a # at beginning of the following line of you want to provide a value for sigma\n",
    "        sigma_value = np.mean(estimate_sigma(img))\n",
    "        \n",
    "        denoise_img = denoise_nl_means(img, \n",
    "                                       h=cut_off_dist*sigma_est,\n",
    "                                       sigma=sigma_value,\n",
    "                                       patch_size=size_of_patches,\n",
    "                                       patch_distance=distance_to_patch)\n",
    "\n",
    "        # Construct the full path for the output image\n",
    "        output_path = os.path.join(nlmeans_output_directory, filename)\n",
    "        \n",
    "        # Save the filtered image\n",
    "        imwrite(output_path, imgout)\n",
    "\n",
    "        # add to list\n",
    "        nlmeans_file_list.append([input_path, output_path])\n",
    "        \n",
    "        print(f\"Processed: {filename} and saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a09225-48f8-4eb4-95cd-12f57a99d34f",
   "metadata": {},
   "source": [
    "## Display a random pair of noisy and denoised images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a4b3ad-9775-49d0-9280-6b9ef0ecd5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get ramdom pair of original und processed images\n",
    "random_pair=random.choice(nlmeans_file_list)\n",
    "orig_img=imread(random_pair[0])\n",
    "median_img=imread(random_pair[1])\n",
    "\n",
    "# display images\n",
    "f=plt.figure(figsize=(16,8))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(orig_img, interpolation='nearest', cmap='gray')\n",
    "plt.title('Original')\n",
    "plt.axis('off');\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(median_img, interpolation='nearest', cmap='gray')\n",
    "plt.title('Non-local means')\n",
    "plt.axis('off');\n",
    "plt.subplots_adjust(wspace=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c6dd5c-a3cd-46a4-8ecc-dee0ae8bcb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img=imread('images/123.tif')\n",
    "sigma_est=np.mean(estimate_sigma(test_img))\n",
    "denoise_img = denoise_nl_means(test_img, h=cut_off_dist*sigma_est, sigma=sigma_est, patch_size=size_of_patches, patch_distance=distance_to_patch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f7f68a-cd95-4ee2-b3f1-55f4e51c6019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display images\n",
    "f=plt.figure(figsize=(16,8))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(test_img, interpolation='nearest', cmap='gray')\n",
    "plt.title('Original')\n",
    "plt.axis('off');\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(denoise_img, interpolation='nearest', cmap='gray')\n",
    "plt.title('Anisotropic Diffusion, ')\n",
    "plt.axis('off');\n",
    "plt.subplots_adjust(wspace=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e62c7d4-114f-4d1f-9c6d-47813a9210b4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 4. StructN2V\n",
    "(source: https://github.com/juglab/n2v/blob/main/examples/2D/structN2V_2D_synth_mem/train_and_predict.ipynb) <br>\n",
    "(documentation: https://github.com/juglab/n2v/tree/main)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85e6993-4e3c-4e98-8924-eab8bd7def5d",
   "metadata": {},
   "source": [
    "## Imports\n",
    "The imports for N2V are seperated from the rest because the installation of these is a little more complex. <br>\n",
    "In case you want to run this notebook locally. <br>\n",
    "The imports at the beginning of this notebook are necessary to use Noise2Void."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1843ad08-5b2c-414b-b3f2-8395c60835c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# We import all our dependencies.\n",
    "from csbdeep.io import save_tiff_imagej_compatible\n",
    "import csv\n",
    "from n2v.internals.N2V_DataGenerator import N2V_DataGenerator\n",
    "from n2v.models import N2VConfig, N2V\n",
    "from n2v.utils.n2v_utils import manipulate_val_data\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5030b656-5a5f-464e-a626-4dcde7df610e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if tf.test.gpu_device_name()=='':\n",
    "  print('You do not have GPU access.')\n",
    "  print('Did you change your runtime ?')\n",
    "  print('If the runtime setting is correct then Google did not allocate a GPU for your session')\n",
    "  print('Expect slow performance. To access GPU try reconnecting later')\n",
    "\n",
    "else:\n",
    "  print('You have GPU access')\n",
    "  !nvidia-smi\n",
    "\n",
    "print('TensorFlow version:')\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de0e97a-1277-480e-9680-cadcdf6ac10a",
   "metadata": {},
   "source": [
    "## Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd72acc0-4795-41ed-9715-51ded800de7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path to where the training images are stored\n",
    "training_source = 'n2v_training_images'\n",
    "\n",
    "# Specifiy how the model should be namend and where it should be saved\n",
    "model_name = \"n2v_pop_test_uno\"\n",
    "model_path = \"n2v_models\"\n",
    "full_model_path = os.path.join(model_path, model_name)\n",
    "\n",
    "# create folder\n",
    "if not os.path.exists(model_path):\n",
    "    os.makedirs(model_path)\n",
    "\n",
    "# Path to where the results should be saved\n",
    "input_directory = 'images'\n",
    "n2v_result_folder = 'N2V_results'\n",
    "\n",
    "# create folder\n",
    "if not os.path.exists(n2v_result_folder):\n",
    "    os.makedirs(n2v_result_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602142a0-ce5e-4702-94b6-ec69ee1d8bf8",
   "metadata": {},
   "source": [
    "## Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaab27d5-7e54-4901-b804-377fdf0fa104",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of epochs: default: 100\n",
    "number_of_epochs =  10\n",
    "\n",
    "#Patch size (pixels): default:64\n",
    "patch_size =  64\n",
    "\n",
    "#Batch size: default: 128\n",
    "batch_size=64\n",
    "\n",
    "#Fraction of training image set used for validation: default: 10\n",
    "percentage_validation=10\n",
    "\n",
    "#Initial learning Rate: default 0.0004\n",
    "initial_learning_rate=0.0004\n",
    "\n",
    "# Should data augmentation be used to diversify the training image data?\n",
    "Use_Data_augmentation = False\n",
    "\n",
    "# Do you want to use Noise2Void or structuredN2V\n",
    "structured = True\n",
    "\n",
    "# If you want to use StructuredN2V, enter the blinding mask here in the same fashion as the example 5x5:\n",
    "blinding_mask = [[0,0,1,0,0],\n",
    "                 [0,0,1,0,0],\n",
    "                 [1,1,1,1,1],\n",
    "                 [0,0,1,0,0],\n",
    "                 [0,0,1,0,0]]\n",
    "\n",
    "\n",
    "if structured:\n",
    "    mask=blinding_mask\n",
    "else:\n",
    "    mask=None "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06f5e62-475d-4ef6-a1b6-e80758361823",
   "metadata": {},
   "source": [
    "## Training Data Preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd593559-a2f3-4044-80b3-0dbc091044cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9120f0-4362-4828-b82c-9427591c0b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create DataGenerator-object.\n",
    "datagen = N2V_DataGenerator()\n",
    "\n",
    "#compatibility to easily change the name of the parameters\n",
    "training_images = training_source\n",
    "imgs = datagen.load_imgs_from_directory(directory = training_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3687974a-d943-4666-9e06-99fdf0dc6c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split patches from the training images\n",
    "Xdata = datagen.generate_patches_from_list(imgs, shape=(patch_size,patch_size), augment=Use_Data_augmentation)\n",
    "\n",
    "shape_of_Xdata = Xdata.shape\n",
    "\n",
    "# create a threshold (10 % patches for the validation)\n",
    "threshold = int(shape_of_Xdata[0]*(percentage_validation/100))\n",
    "# split the patches into training patches and validation patches\n",
    "X = Xdata[threshold:]\n",
    "X_val = Xdata[:threshold]\n",
    "print(Xdata.shape[0],\"patches created.\")\n",
    "print(threshold,\"patch images for validation (\",percentage_validation,\"%).\")\n",
    "print(Xdata.shape[0]-threshold,\"patch images for training.\")\n",
    "\n",
    "#Here we automatically define number_of_step in function of training data and batch size\n",
    "#number_of_steps= int(X.shape[0]/batch_size)+1\n",
    "number_of_steps= int(X.shape[0]/batch_size)+1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbc37ec-2b11-46a6-9e54-98acf0c47635",
   "metadata": {},
   "source": [
    "## Model configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba57c29-2ee0-4d07-a5c6-7a3aa574b70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a Config object\n",
    "config = N2VConfig(X, unet_kern_size=3,\n",
    "                   train_steps_per_epoch=number_of_steps, train_epochs=number_of_epochs,\n",
    "                   train_loss='mse', batch_norm=True, train_batch_size=batch_size, n2v_perc_pix=0.198,\n",
    "                   n2v_manipulator='uniform_withCP', n2v_neighborhood_radius=5, train_learning_rate = initial_learning_rate,\n",
    "                  structN2Vmask=mask)\n",
    "\n",
    "# Let's look at the parameters stored in the config-object.\n",
    "vars(config)\n",
    "\n",
    "# create network model.\n",
    "model = N2V(config=config, name=model_name, basedir=model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b095d15b-1bf6-4e9d-8fd9-c183258bce17",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700d3538-e07f-474c-9c4d-22e9bea7eacf",
   "metadata": {},
   "source": [
    "### There will be an empty AssertionError: at the end of the training. You can ignore this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05680558-6d67-4c79-a11c-25c8c2d40b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "history = model.train(X, X_val)\n",
    "print(\"Training, done.\")\n",
    "\n",
    "# convert the history.history dict to a pandas DataFrame:\n",
    "lossData = pd.DataFrame(history.history)\n",
    "\n",
    "if os.path.exists(os.path.join(full_model_path, \"Quality Control\")):\n",
    "  shutil.rmtree(os.path.join(full_model_path, \"Quality Control\"))\n",
    "\n",
    "os.makedirs(os.path.join(full_model_path, \"Quality Control\"))\n",
    "\n",
    "# The training evaluation.csv is saved (overwrites the Files if needed).\n",
    "lossDataCSVpath = os.path.join(full_model_path, \"Quality Control\", \"training_evaluation.csv\")\n",
    "with open(lossDataCSVpath, 'w') as f:\n",
    "  writer = csv.writer(f)\n",
    "  writer.writerow(['loss','val_loss', 'learning rate'])\n",
    "  for i in range(len(history.history['loss'])):\n",
    "    writer.writerow([history.history['loss'][i], history.history['val_loss'][i], history.history['lr'][i]])\n",
    "\n",
    "# Displaying the time elapsed for training\n",
    "dt = time.time() - start\n",
    "mins, sec = divmod(dt, 60)\n",
    "hour, mins = divmod(mins, 60)\n",
    "print(\"Time elapsed:\",hour, \"hour(s)\",mins,\"min(s)\",round(sec),\"sec(s)\")\n",
    "\n",
    "model.export_TF(name='Noise2Void',\n",
    "                description='Noise2Void',\n",
    "                authors=[\"Lucas Fortune\"],\n",
    "                test_img=X_val[0,...,0], axes='YX',\n",
    "                patch_shape=(patch_size, patch_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae9beff-c7a5-4315-9433-1f29aaed122d",
   "metadata": {},
   "source": [
    "## Quality control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8814ada1-4cee-4a47-aa0b-c50f979add79",
   "metadata": {},
   "outputs": [],
   "source": [
    "lossDataFromCSV = []\n",
    "vallossDataFromCSV = []\n",
    "\n",
    "with open(os.path.join(full_model_path, \"Quality Control\", \"training_evaluation.csv\"), \"r\") as csvfile:\n",
    "    csvRead = csv.reader(csvfile, delimiter=',')\n",
    "    next(csvRead)\n",
    "    for row in csvRead:\n",
    "        lossDataFromCSV.append(float(row[0]))\n",
    "        vallossDataFromCSV.append(float(row[1]))\n",
    "\n",
    "epochNumber = range(len(lossDataFromCSV))\n",
    "plt.figure(figsize=(15,10))\n",
    "\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(epochNumber,lossDataFromCSV, label='Training loss')\n",
    "plt.plot(epochNumber,vallossDataFromCSV, label='Validation loss')\n",
    "plt.title('Training loss and validation loss vs. epoch number (linear scale)')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch number')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.semilogy(epochNumber,lossDataFromCSV, label='Training loss')\n",
    "plt.semilogy(epochNumber,vallossDataFromCSV, label='Validation loss')\n",
    "plt.title('Training loss and validation loss vs. epoch number (log scale)')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch number')\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(full_model_path, 'Quality Control/lossCurvePlots.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5be2d5-2592-4053-b1b8-57697398a03c",
   "metadata": {},
   "source": [
    "## Using the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0021019-dc9a-4456-8560-e779e6adf6d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954b45c5-a8c7-4233-8c3d-cafffac5242f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n2v_file_list = []\n",
    "\n",
    "#Activate the pretrained model.\n",
    "config = None\n",
    "model = N2V(config, model_name, basedir=model_path)\n",
    "\n",
    "# Loop through the files\n",
    "for r, d, f in os.walk(input_directory):\n",
    "    for file in f:\n",
    "        base_filename = os.path.basename(file)\n",
    "        input_train = imread(os.path.join(r, file))\n",
    "        pred_train = model.predict(input_train, axes='YX', n_tiles=(2,1))\n",
    "        save_tiff_imagej_compatible(os.path.join(n2v_result_folder, base_filename), pred_train, axes='YX')\n",
    "\n",
    "        # add to list\n",
    "        in_path = input_directory+'/'+file\n",
    "        out_path = n2v_result_folder+'/'+file\n",
    "        n2v_file_list.append([in_path, out_path])\n",
    "        \n",
    "        print(f\"Processed: {base_filename} and saved to {n2v_result_folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8a4b0f-73f8-41f7-9217-a42629784ddf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "69a062f8-4682-4ac3-9d13-fe74e1096624",
   "metadata": {},
   "source": [
    "## Display a random pair of noisy and denoised images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e85c81-ba49-4540-9ea0-a53ba93c5774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get ramdom pair of original und processed images\n",
    "random_pair=random.choice(n2v_file_list)\n",
    "orig_img=imread(random_pair[0])\n",
    "median_img=imread(random_pair[1])\n",
    "\n",
    "# display images\n",
    "f=plt.figure(figsize=(16,8))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(orig_img, interpolation='nearest', cmap='gray')\n",
    "plt.title('Original')\n",
    "plt.axis('off');\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(median_img, interpolation='nearest', cmap='gray')\n",
    "plt.title('Noise2Void')\n",
    "plt.axis('off');\n",
    "plt.subplots_adjust(wspace=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67eee27a-9ab0-481d-9380-8147f7784122",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
